# -*- coding: utf-8 -*-
"""AI/ML PROJECT SHIPMENT SURE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14QSvo_nt6TNg0LSH7EmPincU5iivyn0N
"""

# Check for missing values
import pandas as pd

# Load the dataset into a pandas DataFrame
df = pd.read_csv('/content/drive/MyDrive/AI ML/Train new.csv')
print("Missing values before imputation:")
print(df.isnull().sum())

# Impute missing values based on data type
for col in df.columns:
    if df[col].isnull().any():
        if df[col].dtype in ['int64', 'float64']:
            df[col].fillna(df[col].mean(), inplace=True)
        else:
            df[col].fillna(df[col].mode()[0], inplace=True)

print("\nMissing values after imputation:")
print(df.isnull().sum())

# Remove duplicate rows
initial_rows = len(df)
df.drop_duplicates(inplace=True)
rows_after_dropping = len(df)

print(f"\nNumber of rows before dropping duplicates: {initial_rows}")
print(f"Number of rows after dropping duplicates: {rows_after_dropping}")

"""#Discriptive Statistics"""

# Select numerical features relevant to the project
numerical_features = ['Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms', 'Reached.on.Time_Y.N']

# Calculate and display descriptive statistics for numerical features
print("Descriptive Statistics for Numerical Features:")
display(df[numerical_features].describe())

# Calculate and display the correlation matrix
print("\nCorrelation Matrix for Numerical Features:")
display(df[numerical_features].corr())

"""# Task
Perform univariate and bivariate analysis on the relevant features of the dataset to understand their relationship with on-time shipment delivery.
"""

relevant_features = [
    'Warehouse_block',
    'Mode_of_Shipment',
    'Customer_care_calls',
    'Customer_rating',
    'Cost_of_the_Product',
    'Prior_purchases',
    'Product_importance',
    'Discount_offered',
    'Weight_in_gms',
    'Reached.on.Time_Y.N' # Include the target variable
]

print("Identified relevant features for predicting on-time shipment delivery:")
print(relevant_features)

"""## Univariate analysis
.

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Create lists of numerical and categorical features
numerical_features = ['Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']
categorical_features = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']

# Univariate analysis for numerical features
for feature in numerical_features:
    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    sns.histplot(data=df, x=feature, kde=True)
    plt.title(f'Distribution of {feature}')

    plt.subplot(1, 2, 2)
    sns.boxplot(data=df, y=feature)
    plt.title(f'Box Plot of {feature}')

    plt.tight_layout()
    plt.show()

# Univariate analysis for categorical features
for feature in categorical_features:
    plt.figure(figsize=(8, 5))
    sns.countplot(data=df, x=feature, palette='viridis')
    plt.title(f'Count Plot of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.show()

"""## Bivariate analysis

Performing bivariate analysis to explore the relationship between relevant features and the target variable ('Reached.on.Time_Y.N').

"""

import matplotlib.pyplot as plt
import seaborn as sns

numerical_features = ['Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']
categorical_features = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']

# Scatter plots for numerical features vs. Reached.on.Time_Y.N
for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.scatterplot(data=df, x=feature, y='Reached.on.Time_Y.N')
    plt.title(f'Scatter Plot of {feature} vs. Reached.on.Time_Y.N')
    plt.show()

# Box plots for numerical features vs. Reached.on.Time_Y.N
for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.boxplot(data=df, x='Reached.on.Time_Y.N', y=feature)
    plt.title(f'Box Plot of {feature} by Reached.on.Time_Y.N')
    plt.show()

# Count plots for categorical features vs. Reached.on.Time_Y.N
for feature in categorical_features:
    plt.figure(figsize=(8, 6))
    sns.countplot(data=df, x=feature, hue='Reached.on.Time_Y.N', palette='viridis')
    plt.title(f'Count Plot of {feature} by Reached.on.Time_Y.N')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.show()

"""#Class Imbalance

"""

import pandas as pd

# Load the dataset into a pandas DataFrame
df = pd.read_csv('/content/drive/MyDrive/AI ML/Train new.csv')

# Calculate the value counts for the 'Reached.on.Time_Y.N' column
class_counts = df['Reached.on.Time_Y.N'].value_counts()

# Calculate the percentage of each class
class_percentages = class_counts / len(df) * 100

# Display the percentages
print("Class distribution for 'Reached.on.Time_Y.N':")
print(class_percentages)

from sklearn.utils import resample

# Separate majority and minority classes
df_majority = df[df['Reached.on.Time_Y.N']==1]
df_minority = df[df['Reached.on.Time_Y.N']==0]

# Upsample minority class
df_minority_upsampled = resample(df_minority,
                                 replace=True,     # sample with replacement
                                 n_samples=len(df_majority),    # to match majority class size
                                 random_state=42) # reproducible results

# Combine majority class with upsampled minority class
df_balanced = pd.concat([df_majority, df_minority_upsampled])

# Display new class counts
print("Class distribution after oversampling:")
print(df_balanced['Reached.on.Time_Y.N'].value_counts())

"""#AFTER 1ST REVIEW

#HEAT MAP
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset into a pandas DataFrame from Google Drive
df = pd.read_csv('/content/drive/MyDrive/AI ML/Train new.csv')

# Calculate the correlation matrix
correlation_matrix = df.corr(numeric_only=True)

# Create a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Feature Correlation Heatmap')
plt.show()

import os
print(os.listdir())

"""enivironment creation"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
# Example: Load CSV dataset
df = pd.read_csv('/content/drive/MyDrive/AI ML/Train new.csv')  # replace with your file path
df.head()

"""handling null values

"""

# Check for missing values
print(df.isnull().sum())

# Separate numerical and categorical columns
num_cols = df.select_dtypes(include=['int64', 'float64']).columns
cat_cols = df.select_dtypes(include=['object']).columns

# Fill missing values
df[num_cols] = df[num_cols].fillna(df[num_cols].mean())       # Replace numerical NaN with mean
df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])  # Replace categorical NaN with mode

print("\nâœ… Missing values handled successfully!")

"""weight:cost
feature engineering cost:weight
"""

# Create a new feature 'Cost_to_Weight_Ratio'
df['Cost_to_Weight_Ratio'] = df['Cost_of_the_Product'] / df['Weight_in_gms']

# Optional: handle any infinite or NaN values
# Safely handle infinite and missing values in Cost_to_Weight_Ratio
import numpy as np
df['Cost_to_Weight_Ratio'] = df['Cost_to_Weight_Ratio'].replace([np.inf, -np.inf], np.nan)
df['Cost_to_Weight_Ratio'] = df['Cost_to_Weight_Ratio'].fillna(df['Cost_to_Weight_Ratio'].mean())

"""SPLIT DATA

splitting training and test data
"""

# Separate independent (X) and dependent (y) variables BEFORE normalization
X = df.drop('Reached.on.Time_Y.N', axis=1)
y = df['Reached.on.Time_Y.N']

# Identify categorical columns in X
cat_cols = X.select_dtypes(include=['object']).columns

# Using Label Encoding on the entire dataset before splitting
encoder = LabelEncoder()
for col in cat_cols:
    X[col] = encoder.fit_transform(X[col])


# Split data into training (80%) and testing (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Further split training data into train + validation
X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

print("âœ… Data split and categorical columns encoded successfully!")

# Further split training data into train + validation
X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

"""encode categorical values"""

# Identify categorical columns in X_train
cat_cols = X_train.select_dtypes(include=['object']).columns

# Using Label Encoding
encoder = LabelEncoder()
for col in cat_cols:
    X_train[col] = encoder.fit_transform(X_train[col])
    X_test[col] = encoder.transform(X_test[col])


print("âœ… Categorical columns encoded successfully!")
X_train.head()

"""normalize numerical functions

"""

# Identify numerical columns excluding the target variable
num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns

scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])


print("âœ… Numerical features normalized successfully!")

"""save preprocessed data"""

df.to_csv('/content/drive/MyDrive/AI ML/cleaned_shipment_data.csv', index=False)
print("âœ… Cleaned data saved successfully!")

display(df.head())

"""duplicate rows"""

# Check how many duplicate rows are present
duplicates = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicates}")

"""#AFTER 2ND REVIEW

MODEL DEVELOPMENT
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
# Load cleaned data
df = pd.read_csv('/content/drive/MyDrive/AI ML/cleaned_shipment_data.csv')

# Check shape and columns
print("Dataset Shape:", df.shape)
print("Columns:", df.columns)

"""HELPER FUNCTION FOR MODEL EVALUATION"""

def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred)

    print(f"\nðŸ“Š {model_name} Performance:")
    print(f"Accuracy: {acc:.3f}")
    print(f"Precision: {prec:.3f}")
    print(f"Recall: {rec:.3f}")
    print(f"F1 Score: {f1:.3f}")
    print(f"ROC-AUC: {roc_auc:.3f}")

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

print("y_train value counts:\n", y_train.value_counts())
print("y_test value counts:\n", y_test.value_counts())

# Identify categorical columns in X_train
cat_cols = X_train.select_dtypes(include=['object']).columns

# Using Label Encoding
encoder = LabelEncoder()
for col in cat_cols:
    X_train[col] = encoder.fit_transform(X_train[col])
    X_test[col] = encoder.transform(X_test[col])

print("âœ… Categorical columns re-encoded successfully!")

"""LOGISTIC REGRESSION"""

log_model = LogisticRegression(max_iter=1000, random_state=42)
log_model.fit(X_train, y_train)
evaluate_model(log_model, X_test, y_test, "Logistic Regression")

"""RANDOM FOREST CLASSIFIER"""

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
evaluate_model(rf_model, X_test, y_test, "Random Forest Classifier")

"""XGBOOST CLASSIFIER"""

df['Reached.on.Time_Y.N'] = df['Reached.on.Time_Y.N'].replace(-1, 0)
print(df['Reached.on.Time_Y.N'].unique())

X = df.drop('Reached.on.Time_Y.N', axis=1)
y = df['Reached.on.Time_Y.N']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(y_train.unique())

from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Identify categorical columns in X_train (assuming they haven't been encoded yet in this cell's context)
# If they have been encoded previously, this step will just re-confirm the columns.
cat_cols = X_train.select_dtypes(include=['object']).columns

# Using Label Encoding to convert categorical features to numerical
encoder = LabelEncoder()
for col in cat_cols:
    X_train[col] = encoder.fit_transform(X_train[col])
    X_test[col] = encoder.transform(X_test[col])

print("âœ… Categorical columns encoded for XGBoost successfully!")

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)
evaluate_model(xgb_model, X_test, y_test, "XGBoost Classifier")

"""KNN MODEL

### K-Nearest Neighbors (KNN) Classifier
"""

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5) # You can adjust the number of neighbors
knn_model.fit(X_train, y_train)
evaluate_model(knn_model, X_test, y_test, "KNN Classifier")

"""DECISON TREE MODEL

### Decision Tree Classifier
"""

from sklearn.tree import DecisionTreeClassifier

dt_model = DecisionTreeClassifier(random_state=42) # You can adjust hyperparameters
dt_model.fit(X_train, y_train)
evaluate_model(dt_model, X_test, y_test, "Decision Tree Classifier")

"""COMPARISON"""

comparison = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost', 'KNN Classifier', 'Decision Tree Classifier'],
    'Accuracy': [0.656, 0.672, 0.651, 0.655, 0.654],
    'Precision': [0.732, 0.782, 0.741, 0.727, 0.709],
    'Recall': [0.669, 0.620, 0.640, 0.676, 0.714],
    'F1 Score': [0.699, 0.692, 0.687, 0.700, 0.711],
    'ROC-AUC': [0.653, 0.684, 0.654, 0.650, 0.640]
})
print(comparison)

"""## Feature Selection and Importance

"""

from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming X_train, X_test, y_train, and y_test are already defined from previous steps
# If not, please run the data splitting and preprocessing steps first.

# Initialize SMOTE
smote = SMOTE(random_state=42)

# Apply SMOTE to the training data
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Print the value counts of the resampled target variable
print("Class distribution after SMOTE:")
print(y_train_resampled.value_counts())

# Initialize a Random Forest model
# Use the resampled training data to fit the model for feature importance
rf_model_importance = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model_importance.fit(X_train_resampled, y_train_resampled)

# Get feature importances
feature_importances = rf_model_importance.feature_importances_

# Create a DataFrame for better visualization
feature_importances_df = pd.DataFrame({
    'Feature': X_train_resampled.columns,
    'Importance': feature_importances
})

# Sort features by importance
feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)

# Visualize feature importances
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importances_df, palette='viridis')
plt.title('Feature Importance from Random Forest')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

print("\nFeature Importances:")
print(feature_importances_df)

from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize a Random Forest model
# We'll use the resampled training data to fit the model for feature importance
rf_model_importance = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model_importance.fit(X_train_resampled, y_train_resampled)

# Get feature importances
feature_importances = rf_model_importance.feature_importances_

# Create a DataFrame for better visualization
feature_importances_df = pd.DataFrame({
    'Feature': X_train_resampled.columns,
    'Importance': feature_importances
})

# Sort features by importance
feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)

# Visualize feature importances
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importances_df, palette='viridis')
plt.title('Feature Importance from Random Forest')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

print("Feature Importances:")
print(feature_importances_df)

"""## Feature engineering


"""

# Create a new feature 'Cost_to_Weight_Ratio'
df['Cost_to_Weight_Ratio'] = df['Cost_of_the_Product'] / df['Weight_in_gms']

# Handle any infinite or NaN values
import numpy as np
df['Cost_to_Weight_Ratio'] = df['Cost_to_Weight_Ratio'].replace([np.inf, -np.inf], np.nan)
df['Cost_to_Weight_Ratio'] = df['Cost_to_Weight_Ratio'].fillna(df['Cost_to_Weight_Ratio'].mean())

print("âœ… 'Cost_to_Weight_Ratio' feature created and handled successfully!")
display(df[['Cost_of_the_Product', 'Weight_in_gms', 'Cost_to_Weight_Ratio']].head())

from sklearn.preprocessing import LabelEncoder, StandardScaler

# Identify categorical columns
cat_cols = df.select_dtypes(include=['object']).columns

# Apply Label Encoding to categorical features
encoder = LabelEncoder()
for col in cat_cols:
    df[col] = encoder.fit_transform(df[col])

print(" Categorical columns encoded successfully!")

# Identify numerical columns excluding the target variable for scaling
num_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('Reached.on.Time_Y.N')

# Apply StandardScaler to numerical features
scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

print(" Numerical features scaled successfully!")

# Display the head of the transformed DataFrame
display(df.head())

"""## Handling class imbalance



"""

# Initialize SMOTE
smote = SMOTE(random_state=42)

# Apply SMOTE to the training data
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Print the value counts of the resampled target variable
print("Class distribution after SMOTE:")
print(y_train_resampled.value_counts())

"""## Hyperparameter tuning


"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install catboost

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# âœ… Regularized versions of models
models = {
    "Logistic Regression": LogisticRegression(C=0.5, max_iter=1000, random_state=42),
    "Decision Tree": DecisionTreeClassifier(max_depth=8, min_samples_split=10, min_samples_leaf=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=10, min_samples_leaf=5, random_state=42, n_jobs=-1),
    "Naive Bayes": GaussianNB(),
    "KNN": KNeighborsClassifier(n_neighbors=9),
    "SVM": SVC(C=0.5, kernel='rbf', gamma='scale', probability=True, random_state=42),
    "XGBoost": XGBClassifier(
        learning_rate=0.05, n_estimators=500, max_depth=6,
        subsample=0.8, colsample_bytree=0.8, reg_lambda=0.5,
        use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(
        learning_rate=0.05, n_estimators=500, max_depth=6, num_leaves=20,
        subsample=0.8, colsample_bytree=0.8, reg_alpha=0.2, reg_lambda=0.5, random_state=42),
    "CatBoost": CatBoostClassifier(
        iterations=500, learning_rate=0.05, depth=6, l2_leaf_reg=5, verbose=False, random_state=42)
}

model_performance = []

# âœ… Train and evaluate each model
for model_name, model in models.items():
    print(f"\nðŸš€ Training {model_name}...")
    model.fit(X_train_resampled, y_train_resampled)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred)

    model_performance.append({
        'Model': model_name,
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1 Score': f1,
        'ROC-AUC': roc_auc
    })

    # Confusion matrix visualization
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu')
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# âœ… Compare results
comparison_df = pd.DataFrame(model_performance).sort_values(by='Accuracy', ascending=False)
print("\nðŸ“Š Model Performance Comparison:")
display(comparison_df)

models = {
    "Logistic Regression": LogisticRegression(C=0.5, max_iter=1000, random_state=42),
    "Decision Tree": DecisionTreeClassifier(max_depth=8, min_samples_split=10, min_samples_leaf=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=10, min_samples_leaf=5, random_state=42, n_jobs=-1),
    "Naive Bayes": GaussianNB(),
    "KNN": KNeighborsClassifier(n_neighbors=9),
    "SVM": SVC(C=0.5, kernel='rbf', gamma='scale', probability=True, random_state=42),
    "XGBoost": XGBClassifier(
        learning_rate=0.05, n_estimators=500, max_depth=6,
        subsample=0.8, colsample_bytree=0.8, reg_lambda=0.5,
        use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(
        learning_rate=0.05, n_estimators=500, max_depth=6, num_leaves=20,
        subsample=0.8, colsample_bytree=0.8, reg_alpha=0.2, reg_lambda=0.5, random_state=42),
    "CatBoost": CatBoostClassifier(
        iterations=500, learning_rate=0.05, depth=6, l2_leaf_reg=5, verbose=False, random_state=42)
}

from sklearn.metrics import classification_report # Import classification_report

# --- Store results ---
results = {}
comparison = []

# Identify categorical columns in X_val
cat_cols_val = X_val.select_dtypes(include=['object']).columns

# Encode categorical columns in X_val using the previously fitted encoder
# Assuming 'encoder' from cell yhNiCWII1AT8 is available
# If not, you might need to re-fit or load the encoder
try:
    for col in cat_cols_val:
        X_val[col] = encoder.transform(X_val[col])
    print("âœ… Categorical columns in X_val encoded successfully!")
except NameError:
    print("Error: LabelEncoder 'encoder' not found. Please ensure the encoding cell was run.")
    # Optionally, re-initialize and fit encoder if it's not available
    # from sklearn.preprocessing import LabelEncoder
    # encoder = LabelEncoder()
    # for col in cat_cols_val:
    #     X_val[col] = encoder.fit_transform(X_val[col])
    # print("âœ… Categorical columns in X_val encoded successfully after re-initialization!")


plt.figure(figsize=(10, 7))
for name, model in models.items():
    print(f"\n Training and evaluating {name}...")

    model.fit(X_train, y_train) # Fit on training data
    y_val_pred = model.predict(X_val)
    y_val_prob = model.predict_proba(X_val)[:, 1]

    # Metrics
    acc = accuracy_score(y_val, y_val_pred)
    prec = precision_score(y_val, y_val_pred)
    rec = recall_score(y_val, y_val_pred)
    f1 = f1_score(y_val, y_val_pred)
    roc_auc = roc_auc_score(y_val, y_val_prob)

    print(f"\nClassification Report for {name}:")
    print(classification_report(y_val, y_val_pred))

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_val, y_val_prob)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.3f})")

    comparison.append({
        "Model": name,
        "Accuracy": round(acc, 4),
        "Precision": round(prec, 4),
        "Recall": round(rec, 4),
        "F1 Score": round(f1, 4),
        "ROC-AUC": round(roc_auc, 4)
    })

# --- Plot ROC Curve ---
plt.plot([0, 1], [0, 1], 'k--')
plt.title("ROC-AUC Curve Comparison")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# --- Final Comparison Table ---
comparison_df = pd.DataFrame(comparison).sort_values(by='ROC-AUC', ascending=False)
print("\nFinal Model Comparison Table:")
print(comparison_df)

import joblib
import os

# Assuming xgb_model is the trained XGBoost model from previous steps
# If you have retrained XGBoost with the resampled data, use that model object.
# For consistency, let's assume the last trained xgb_model is the one you want to save.

# Define the path to save the model in Google Drive
drive_path = '/content/drive/MyDrive/AI ML/'
model_filename = 'xgboost_model.joblib'
full_model_path = os.path.join(drive_path, model_filename)

# Ensure the directory exists
os.makedirs(drive_path, exist_ok=True)

# Save the model to a file in Google Drive
joblib.dump(xgb_model, full_model_path)

print(f"âœ… XGBoost model saved successfully to '{full_model_path}'")

"""#MODEL DEPLOYMENT"""

import joblib

# Load your previously saved model
xgb_model = joblib.load("/content/drive/MyDrive/AI ML/xgboost_model.joblib")

# Save again as .pkl for deployment
joblib.dump(xgb_model, "/content/drive/MyDrive/AI ML/model.pkl")

"""#STREAMLIT UI"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_streamlit.py
# import streamlit as st
# import joblib
# import numpy as np
# 
# # -------------------------
# # Load trained model
# # -------------------------
# model = joblib.load("/content/drive/MyDrive/AI ML/model.pkl")
# 
# # -------------------------
# # Page Configuration
# # -------------------------
# st.set_page_config(page_title="ShipmentSure", layout="centered")
# st.title("ðŸšš ShipmentSure - Delivery Prediction App")
# st.markdown("### Predict whether your shipment will arrive on time!")
# 
# # -------------------------
# # Input Fields
# # -------------------------
# st.subheader("ðŸ“¦ Enter Shipment Details")
# 
# # Categorical mappings (same as training)
# warehouse_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'F': 4}
# shipment_mode_map = {'Ship': 0, 'Flight': 1, 'Road': 2}
# importance_map = {'low': 0, 'medium': 1, 'high': 2}
# gender_map = {'M': 0, 'F': 1}
# 
# # Collect inputs
# ID = st.number_input("Shipment ID", min_value=1, step=1)
# Warehouse_block = st.selectbox("Warehouse Block", list(warehouse_map.keys()))
# Mode_of_Shipment = st.selectbox("Mode of Shipment", list(shipment_mode_map.keys()))
# Customer_care_calls = st.slider("Customer Care Calls", 1, 10, 3)
# Customer_rating = st.slider("Customer Rating", 1, 5, 4)
# Cost_of_the_Product = st.number_input("Cost of Product", min_value=1.0, step=1.0)
# Prior_purchases = st.slider("Prior Purchases", 0, 10, 2)
# Product_importance = st.selectbox("Product Importance", list(importance_map.keys()))
# Gender = st.selectbox("Customer Gender", list(gender_map.keys()))
# Discount_offered = st.number_input("Discount Offered (%)", min_value=0.0, step=0.5)
# Weight_in_gms = st.number_input("Weight (grams)", min_value=100.0, step=50.0)
# Cost_to_Weight_Ratio = st.number_input("Cost to Weight Ratio", min_value=0.0, step=0.001)
# 
# # -------------------------
# # Prediction Logic
# # -------------------------
# if st.button("ðŸš€ Predict Delivery Status"):
#     X = np.array([[
#         ID,
#         warehouse_map[Warehouse_block],
#         shipment_mode_map[Mode_of_Shipment],
#         Customer_care_calls,
#         Customer_rating,
#         Cost_of_the_Product,
#         Prior_purchases,
#         importance_map[Product_importance],
#         gender_map[Gender],
#         Discount_offered,
#         Weight_in_gms,
#         Cost_to_Weight_Ratio
#     ]])
# 
#     prediction = model.predict(X)[0]
#     probability = model.predict_proba(X)[0][1] if hasattr(model, "predict_proba") else None
# 
#     result = "ðŸŸ¢ On Time" if prediction == 1 else "ðŸ”´ Delayed"
#     st.subheader("ðŸ“Š Prediction Result:")
#     st.write(f"**Status:** {result}")
#     if probability:
#         st.write(f"**Confidence:** {probability:.2%}")
#